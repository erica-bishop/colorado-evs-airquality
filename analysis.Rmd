---
title: "EVs and local air quality"
author: "Erica Bishop"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
library(here)
library(janitor)
library(lubridate)
#library(datapasta)
library(zoo)
library(ggpubr)
library(gridExtra)
library(gt)
library(modelr)
library(feasts)
library(tsibble)

```


```{r}
#set up data directory
datadir <- ("/Users/ericabishop/Documents/MEDS-fall-classwork/EDS222-stats/final_project/data")


#read in EV data and format dates
co_evs <- read_csv(file.path(datadir, "co_ev_registrations_public.csv")) |> 
  janitor::clean_names() 

#format dates
co_evs <- co_evs |> 
  mutate(registration_valid_date = lubridate::mdy(registration_valid_date),
         registration_expiration_date = lubridate::mdy(registration_expiration_date))

```
EV data: downloaded from https://www.atlasevhub.com/materials/state-ev-registration-data/#data
- zip codes are a hot mess (multiple different formats / lengths?)
- over 1300 unique zips (should be no more than 500 or so)
- date range: January 2010 - July 2022
- includes fuel cell, plug in hybrid, and EV
- NOT using cumulative counts becuase this dataset includes original registrations and renewals without distinction, so according the the recommendations from the data source, treating like a snapshot in time

Air Quality data from the EPA's Air Data: https://www.epa.gov/outdoor-air-quality-data
- from https://aqs.epa.gov/aqsweb/airdata/download_files.html
- Daily AQI, Daily Ozone, and Annual AQI data by county


```{r}

#read in raw daily AQI data

daily_aqi_raw_10 <- read_csv(file.path(datadir, "daily_county_aqi", "daily_aqi_by_county_2010.csv"))
daily_aqi_raw_11 <- read_csv(file.path(datadir, "daily_county_aqi", "daily_aqi_by_county_2011.csv"))
daily_aqi_raw_12 <- read_csv(file.path(datadir, "daily_county_aqi", "daily_aqi_by_county_2012.csv"))
daily_aqi_raw_13 <- read_csv(file.path(datadir, "daily_county_aqi", "daily_aqi_by_county_2013.csv"))
daily_aqi_raw_14 <- read_csv(file.path(datadir, "daily_county_aqi", "daily_aqi_by_county_2014.csv"))
daily_aqi_raw_15 <- read_csv(file.path(datadir, "daily_county_aqi", "daily_aqi_by_county_2015.csv"))
daily_aqi_raw_16 <- read_csv(file.path(datadir, "daily_county_aqi", "daily_aqi_by_county_2016.csv"))
daily_aqi_raw_17 <- read_csv(file.path(datadir, "daily_county_aqi", "daily_aqi_by_county_2017.csv"))
daily_aqi_raw_18 <- read_csv(file.path(datadir, "daily_county_aqi", "daily_aqi_by_county_2018.csv"))
daily_aqi_raw_19 <- read_csv(file.path(datadir, "daily_county_aqi", "daily_aqi_by_county_2019.csv"))
daily_aqi_raw_20 <- read_csv(file.path(datadir, "daily_county_aqi", "daily_aqi_by_county_2020.csv"))
daily_aqi_raw_21 <- read_csv(file.path(datadir, "daily_county_aqi", "daily_aqi_by_county_2021.csv"))
daily_aqi_raw_22 <- read_csv(file.path(datadir, "daily_county_aqi", "daily_aqi_by_county_2022.csv"))

```

```{r}
#Function to filter dfs to just counties in Colorado
filter_CO <- function(df) {
  df_filtered <- df |> 
    filter(`State Name` == "Colorado") |> 
    clean_names()
  return(df_filtered)
}

#run function on data frames:
daqi_10_CO <- filter_CO(daily_aqi_raw_10)
daqi_11_CO <- filter_CO(daily_aqi_raw_11)
daqi_12_CO <- filter_CO(daily_aqi_raw_12)
daqi_13_CO <- filter_CO(daily_aqi_raw_13)
daqi_14_CO <- filter_CO(daily_aqi_raw_14)
daqi_15_CO <- filter_CO(daily_aqi_raw_15)
daqi_16_CO <- filter_CO(daily_aqi_raw_16)
daqi_17_CO <- filter_CO(daily_aqi_raw_17)
daqi_18_CO <- filter_CO(daily_aqi_raw_18)
daqi_19_CO <- filter_CO(daily_aqi_raw_19)
daqi_20_CO <- filter_CO(daily_aqi_raw_20)
daqi_21_CO <- filter_CO(daily_aqi_raw_21)
daqi_22_CO <- filter_CO(daily_aqi_raw_22)
  
#join using rbind
daqi_CO <- rbind(daqi_10_CO, daqi_11_CO, daqi_12_CO, daqi_13_CO, daqi_14_CO, daqi_15_CO, daqi_16_CO, daqi_17_CO, daqi_18_CO, daqi_19_CO, daqi_20_CO, daqi_21_CO, daqi_22_CO)

daqi_CO <- daqi_CO |> 
  rename(date_local = date) #renaming in case joining to ozone data

```

```{r}

#read in daily ozone data
daily_ozone_2010 <- read_csv(file.path(datadir, "daily_summary_ozone", "daily_44201_2010.csv"))
daily_ozone_2011 <- read_csv(file.path(datadir, "daily_summary_ozone", "daily_44201_2011.csv"))
daily_ozone_2012 <- read_csv(file.path(datadir, "daily_summary_ozone", "daily_44201_2012.csv"))
daily_ozone_2013 <- read_csv(file.path(datadir, "daily_summary_ozone", "daily_44201_2013.csv"))
daily_ozone_2014 <- read_csv(file.path(datadir, "daily_summary_ozone", "daily_44201_2014.csv"))
daily_ozone_2015 <- read_csv(file.path(datadir, "daily_summary_ozone", "daily_44201_2015.csv"))
daily_ozone_2016 <- read_csv(file.path(datadir, "daily_summary_ozone", "daily_44201_2016.csv"))
daily_ozone_2017 <- read_csv(file.path(datadir, "daily_summary_ozone", "daily_44201_2017.csv"))
daily_ozone_2018 <- read_csv(file.path(datadir, "daily_summary_ozone", "daily_44201_2018.csv"))
daily_ozone_2019 <- read_csv(file.path(datadir, "daily_summary_ozone", "daily_44201_2019.csv"))
daily_ozone_2020 <- read_csv(file.path(datadir, "daily_summary_ozone", "daily_44201_2020.csv"))
daily_ozone_2021 <- read_csv(file.path(datadir, "daily_summary_ozone", "daily_44201_2021.csv"))
daily_ozone_2022 <- read_csv(file.path(datadir, "daily_summary_ozone", "daily_44201_2022.csv"))

#filter to just CO
dozo_10_CO <- filter_CO(daily_ozone_2010)
dozo_11_CO <- filter_CO(daily_ozone_2011)
dozo_12_CO <- filter_CO(daily_ozone_2012)
dozo_13_CO <- filter_CO(daily_ozone_2013)
dozo_14_CO <- filter_CO(daily_ozone_2014)
dozo_15_CO <- filter_CO(daily_ozone_2015)
dozo_16_CO <- filter_CO(daily_ozone_2016)
dozo_17_CO <- filter_CO(daily_ozone_2017)
dozo_18_CO <- filter_CO(daily_ozone_2018)
dozo_19_CO <- filter_CO(daily_ozone_2019)
dozo_20_CO <- filter_CO(daily_ozone_2020)
dozo_21_CO <- filter_CO(daily_ozone_2021)
dozo_22_CO <- filter_CO(daily_ozone_2022)

#combine into one df with rbind
dozo_CO <- rbind(dozo_10_CO, dozo_11_CO, dozo_12_CO, dozo_13_CO, dozo_14_CO, dozo_15_CO, dozo_16_CO, dozo_17_CO, dozo_18_CO, dozo_19_CO, dozo_20_CO, dozo_21_CO)

```

```{r}
#remove precursor datasets from memory to free up space
# rm(dozo_10_CO, dozo_11_CO, dozo_12_CO, dozo_13_CO, dozo_14_CO, dozo_15_CO, dozo_16_CO, dozo_17_CO, dozo_18_CO, dozo_19_CO, dozo_20_CO, dozo_21_CO)
# rm(daqi_10_CO, daqi_11_CO, daqi_12_CO, daqi_13_CO, daqi_14_CO, daqi_15_CO, daqi_16_CO, daqi_17_CO, daqi_18_CO, daqi_19_CO, daqi_20_CO, daqi_21_CO, daqi_22_CO)
# rm(daily_aqi_raw_10, daily_aqi_raw_11, daily_aqi_raw_12, daily_aqi_raw_13, daily_aqi_raw_14, daily_aqi_raw_15, daily_aqi_raw_16, daily_aqi_raw_17, daily_aqi_raw_18, daily_aqi_raw_19, daily_aqi_raw_20, daily_aqi_raw_21, daily_aqi_raw_22)
#rm(daily_ozone_2010, daily_ozone_2011, daily_ozone_2012, daily_ozone_2013, daily_ozone_2014, daily_ozone_2015, daily_ozone_2016, daily_ozone_2017, daily_ozone_2018, daily_ozone_2019, daily_ozone_2020, daily_ozone_2021, daily_ozone_2022)

```


```{r}

#read in county data, drop state column
co_counties <- read_csv(file.path(datadir, "CO_counties.csv")) |> 
  clean_names() |> 
  select("county", "zip_code")

#attach county names associated with zip code to co_evs
co_evs_counties <- left_join(co_evs, co_counties, by = "zip_code")

#rename date column to join
co_evs_counties <- co_evs_counties |> 
  rename(date_local = registration_valid_date)

#join ev and ozone data
co_evs_ozone <- full_join(dozo_CO, co_evs_counties, by = "date_local")
#DON"T USE THAT DF ITS GARBAGE


```


Selecting variables of interest and joining by county (rather than zip codes becasue those are a bit of a mess)

```{r}
#manipulate variables of interest into one DF - BY COUNTY

#select columns of interest from EVs into new DF
evs_clean <- co_evs_counties |> 
  select("county", "date_local", "zip_code") |> 
  mutate(my_date = as.yearmon(date_local))
  
#just using ozone data for now
#select columns of interest from ozone into new DF
ozone_clean <- dozo_CO |> 
  select("date_local", "units_of_measure", "parameter_name", "aqi", "county_name", "local_site_name", "x1st_max_value", "x1st_max_hour", "arithmetic_mean") |> 
  mutate(my_date = as.yearmon(date_local)) |> 
  rename(county = county_name)

```

Run some summary statistics to get an idea of what each variable of interest looks like: 
```{r}

evs_summary <- evs_clean |> 
  group_by(my_date) |> 
  summarize(ev_reg_count = n())


ozone_summary <- ozone_clean |> 
  group_by(my_date) |> 
  summarize(monthly_ozone_avg_ppm = mean(arithmetic_mean))

#combine summary tables and include cumulative registration

my_summary <- left_join(evs_summary, ozone_summary, by  = "my_date") #|> 
#   mutate(cum_evreg_since2010 = cumsum(ev_reg_count))


#create a table that retains county data??? maybe filter to just Denver

#den_summary <- left_join(ozone_clean, evs_clean, by = "county")

#still doesn't really make sense to have ev reg and ozone observations in the same df...
```

Try out using the county summary to maybe look at just a few counties
Top 5 most populous counties in Colorado (in order): El Paso (Colorado SPrings), Denver, Arapahoe, Jefferson, Adams (all with populations over 500k)
```{r}
#try a county summary

ev_sum_counties <- evs_clean |> 
  group_by(county, my_date) |> 
  summarise(ev_reg = n())

ozone_sum_counties <- ozone_clean |> 
  group_by(county, my_date) |> 
  summarise(avg_oz = mean(arithmetic_mean))


county_sum <- left_join(ev_sum_counties, ozone_summary)

topcounties <- county_sum |> 
  filter(county %in% c("El Paso County", "Denver County", "Arapahoe County", "Jefferson County", "Adams Counties"))


```
Data exploration:

```{r}
ev_plot <- ggplot(data = my_summary,
       aes(x = my_date,
           y = ev_reg_count)) +
  geom_line()

oz_plot <- ggplot(data = my_summary,
       aes(x = my_date,
           y = monthly_ozone_avg_ppm)) +
  geom_line()



ev_plot
oz_plot

oz_ev_plot <- ggplot(data = my_summary,
                     aes(x = ev_reg_count,
                         y = monthly_ozone_avg_ppm)) +
  geom_point()

oz_ev_plot


counties_plot <- ggplot(data = topcounties,
                        aes(x = ev_reg,
                            y = monthly_ozone_avg_ppm,
                            col = county)) +
  geom_point()

counties_plot

```

### Part 1: Look for a model - is there a relationship between any of the variables?

- find correlation
- find covariance
- scatter plot

```{r}
#investigate correlation
cor(my_summary$ev_reg_count, my_summary$monthly_ozone_avg_ppm, use = "complete.obs")
#ver small negative correlation

```

Maybe there is a long-term trend in the time-series data of the ozone data - try running a classical decomposition to see if there's a long-term trend

To recover seasonality separately from the long run trend, we will use a classical decomposition. That is, we wish to decompose total deaths $D_t$ into a trend component $T_t$, a seasonal component $S_t$, and a random component $R_t$. We will assume an additive model describes our data, as we don't see evidence in the above plot that the magnitude of seasonality is changing over time:

$$D_t = S_t + T_t + R_t$$

```{r}
# ozone_ts <- dozo_CO |> 
#   select("x1st_max_value", "date_local") |> 
#   as_tsibble(index = date_local, key = )


ozone_ts <- as_tibble(my_summary) |> 
  select("my_date", "monthly_ozone_avg_ppm") |> 
  mutate(my_date = yearmonth(my_date)) |> 
  as_tsibble()  #key = monthly_ozone_avg_ppm, index = my_date) #for some reason decomp doesn't work with these arguments specified
 
# esales <- arrow::read_feather("data/esales.feather")
# esales %>%
#   dplyr::select(date, sales_GWh = value) -> esales_tbl
# esales_tbl %>% as_tsibble(index = date) -> elsales_tbl_ts


ozone_decomp <- as_tsibble(ozone_ts) |> 
  model(
    classical_decomposition(monthly_ozone_avg_ppm, type = "additive")
  ) |> 
  components() |> 
  autoplot() +
  labs(title = "Classical additive decomposition of monthly ozone")

ozone_decomp

```

From the above time series analysis, its clear that seasonal variations and even random variations account for most of the ozone pollutio, the long run trend is very weak. 

Take a look at a decomposition of ev registrations to see if there is any similar pattern, or perhaps we can 

```{r}

ev_ts <- as_tibble(my_summary) |> 
  select("my_date", "ev_reg_count") |> 
  mutate(my_date = yearmonth(my_date)) |> 
  as_tsibble()

ev_decomp <- ev_ts |> 
  model(
    classical_decomposition(ev_reg_count, type = "additive")
  ) |> 
  components() |> 
  autoplot() +
  labs(title = "Classical additive decomposition of ev registrations")

ev_decomp

```


Now to examine the relationship between these variables:


Run a simple linear regression model: 
$$\text{monthly_ozone_avg_ppm} = \beta_0 + \beta_1 \text{cum_evreg_since2010} + \epsilon$$


```{r}
#regress ozone days on ev registration

mod <- lm(monthly_ozone_avg_ppm ~ ev_reg_count, data = my_summary)

print(summary(mod))

#plot the model
ggplot(data = my_summary,
       aes(x = ev_reg_count,
           y = monthly_ozone_avg_ppm)) +
  geom_point() +
  geom_line(data = augment(mod),
            aes(y = .fitted)) +
  labs(x = "Monthly EV Registrations in Colorado",
       y = "Monthly average ozone (ppm)")

```

Does the county play a role at all? (not sure it even makes sense to run an interaction model, but perhaps just looking at the top counties individually)
```{r}




```


###

IF there's nothing significant, try looking at the number of ozone action alert days to see if there's a correlation:
https://docs.google.com/spreadsheets/d/1BHUei0iDaE2EvSIrD4KAN9xy9mQQWhLDAgZtA1iFSl4/edit#gid=1498430605 


### Part 2: Test Hypothesis

Null Hypothesis: beta_1 (slope) = 0 (no relationship between ozone and # of EVs)
Alternate Hypothesis: beta_1 != 0 (or is negative?)

```{r}






```















